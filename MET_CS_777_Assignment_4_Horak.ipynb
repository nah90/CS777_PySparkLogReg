{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MET CS 777 Assignment 4 Horak",
      "provenance": [],
      "authorship_tag": "ABX9TyMbzmTluv+KxrnbhbtcLSUi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nah90/CS777_PySparkLogReg/blob/main/MET_CS_777_Assignment_4_Horak.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --ignore-installed -q pyspark==3.2.1"
      ],
      "metadata": {
        "id": "Q-NfVgdyDh4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBbFZX1lDXzC"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import sys\n",
        "import numpy as np\n",
        "from operator import add\n",
        "\n",
        "from operator import add\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()\n",
        "sc = SparkContext.getOrCreate()"
      ],
      "metadata": {
        "id": "3neePetONmuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_words = 10000"
      ],
      "metadata": {
        "id": "fmmMx5fINjg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buildArray(listOfIndices):\n",
        "    \n",
        "    returnVal = np.zeros(n_words)\n",
        "    for index in listOfIndices:\n",
        "        returnVal[index] = returnVal[index] + 1\n",
        "    mysum = np.sum(returnVal)\n",
        "    returnVal = np.divide(returnVal, mysum)\n",
        "    return returnVal"
      ],
      "metadata": {
        "id": "iYVFkKfGDcPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! wget -q https://storage.googleapis.com/met-cs-777-data/SmallTrainingData.txt.bz2\n",
        "\n",
        "# Use this code to read the data\n",
        "courtFile = 'SmallTrainingData.txt.bz2'\n",
        "corpus = sc.textFile(courtFile, 1)"
      ],
      "metadata": {
        "id": "4LtK1fPeDdy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyAndText = corpus.map(lambda x : (x[x.index('id=\"') + 4 : x.index('\" url=')], x[x.index('\">') + 2:][:-6]))\n",
        "regex = re.compile('[^a-zA-Z]')\n",
        "keyAndListOfWords = keyAndText.map(lambda x : (str(x[0]), regex.sub(' ', str(x[1])).lower().split()))\n",
        "\n",
        "topNWords = keyAndListOfWords.flatMap(lambda x: [(a,1) for a in x[1]]).reduceByKey(add).top(n_words, key = lambda x: x[1])\n",
        "\n",
        "dictionary = sc.parallelize(range(n_words)).map(lambda x : (topNWords[x][0], x))\n",
        "dict_data = dictionary.collectAsMap()\n",
        "sc.broadcast(dict_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpYFTB1yJXoc",
        "outputId": "6109de4b-0e29-40b5-cf71-7bbaf2d3d867"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.broadcast.Broadcast at 0x7fe9f61d3590>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 1\n",
        "\n",
        "def getPosition (inputWordList):\n",
        "  for e in inputWordList:\n",
        "    lookup = dict_data.get(e)\n",
        "    if lookup != None:\n",
        "      print(\"word: \", e, \"-\", \"frequency: \", lookup)\n",
        "    else:\n",
        "      print(\"word: \", e, \"-\", \"frequency: \",-1)\n",
        "\n",
        "word_checks = ['applicant', 'and', 'attack', 'protein', 'car', 'court']#, 'humonginormous']\n",
        "\n",
        "getPosition(word_checks) #Check word frequencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6dXwiqkQCiK",
        "outputId": "a98cf416-f532-4459-863b-7d90fe828dd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word:  applicant - frequency:  346\n",
            "word:  and - frequency:  2\n",
            "word:  attack - frequency:  502\n",
            "word:  protein - frequency:  3014\n",
            "word:  car - frequency:  608\n",
            "word:  court - frequency:  149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 2\n",
        "\n",
        "allDictionaryWords = keyAndListOfWords.flatMap(lambda x: ((j, x[0]) for j in x[1])).map(lambda x: (x[0], (x[1], dict_data.get(x[0]))) if x[0] in dict_data.keys() else None).filter(lambda x: x!=None)\n",
        "\n",
        "allDocsAsNumpyArrays = allDictionaryWords.map(lambda x: (x[1][0], x[1][1])).groupByKey().map(lambda x: (x[0], buildArray(x[1])))"
      ],
      "metadata": {
        "id": "94CeOI5WUCue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "traindata = allDocsAsNumpyArrays.map(lambda x: (1 if 'AU' in x[0] else 0, np.append(x[1],1)))\n",
        "traindata.cache()\n",
        "train_size = traindata.count()\n",
        "\n",
        "print(traindata.take(10))"
      ],
      "metadata": {
        "id": "JzJs4-IQmXph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ece38f4-77f6-4315-d173-2d2397052c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, array([0.11813274, 0.06732296, 0.02349952, ..., 0.        , 0.        ,\n",
            "       1.        ])), (1, array([0.11467201, 0.05658488, 0.03855784, ..., 0.        , 0.        ,\n",
            "       1.        ])), (1, array([0.0742913 , 0.0400782 , 0.01075269, ..., 0.00195503, 0.00391007,\n",
            "       1.        ])), (1, array([0.06669866, 0.04534549, 0.02855086, ..., 0.        , 0.        ,\n",
            "       1.        ])), (1, array([8.68935554e-02, 4.41708907e-02, 2.53439537e-02, ...,\n",
            "       3.62056481e-04, 0.00000000e+00, 1.00000000e+00])), (1, array([0.11010421, 0.0357952 , 0.01857725, ..., 0.        , 0.        ,\n",
            "       1.        ])), (1, array([0.09835336, 0.0400534 , 0.02714731, ..., 0.        , 0.        ,\n",
            "       1.        ])), (1, array([0.09986541, 0.04253028, 0.01588156, ..., 0.        , 0.        ,\n",
            "       1.        ])), (1, array([0.07306122, 0.04683673, 0.01642857, ..., 0.        , 0.        ,\n",
            "       1.        ])), (1, array([0.0866426 , 0.03936183, 0.02084546, ..., 0.        , 0.        ,\n",
            "       1.        ]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def LogisticRegression(traindata,\n",
        "                       max_iteration,\n",
        "                       learningRate,\n",
        "                       regularization,\n",
        "                       mini_batch_size,\n",
        "                       train_size):\n",
        "\n",
        "    #Initialization\n",
        "    prev_cost = 0\n",
        "    L_cost = []\n",
        "    parameter_size = len(traindata.take(1)[0][1])\n",
        "    np.random.seed(805) #My area code\n",
        "    parameter_vector = np.zeros(parameter_size) #Initialize with zeros\n",
        "    \n",
        "    for i in range(max_iteration):\n",
        "\n",
        "        bc_weights = parameter_vector\n",
        "\n",
        "        mini_batch = traindata.sample(False, mini_batch_size / train_size, 1 + i) #Use mini-batch procedure\n",
        "\n",
        "        res = mini_batch.treeAggregate((np.zeros(parameter_size), 0, 0), lambda x, y: (x[0] + y[1] * (-y[0] + (1 - 1/(np.exp(np.dot(y[1], bc_weights)) + 1))),\\\n",
        "                          x[1] + y[0] * (-(np.dot(y[1], bc_weights))) + np.log(1 + np.exp(np.dot(y[1], bc_weights))), x[2] + 1), add)\n",
        "\n",
        "        cost =  res[1] + regularization * (np.square(parameter_vector).sum()) #Regularization l2\n",
        "        \n",
        "        #Calculate gradients\n",
        "        gradient_derivative = (1.0 / res[2]) * res[0] + 2 * regularization * parameter_vector #Regularization l2\n",
        "        \n",
        "        #Sigmoid optimizer\n",
        "        parameter_vector = parameter_vector - learningRate * gradient_derivative #Standard SGD\n",
        "          \n",
        "\n",
        "        print(i+1, \" Cost =\", cost)\n",
        "        \n",
        "        prev_cost = cost\n",
        "        L_cost.append(cost)\n",
        "        \n",
        "    return parameter_vector, L_cost\n",
        "\n",
        "pv, l_cost = LogisticRegression(traindata, 50, 29.75, 0.0002475, 256, train_size) #Smaller size for Small dataset than with Large\n",
        "\n",
        "traindata.unpersist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcwxELuqrvaR",
        "outputId": "13a3a1b7-35cf-4d6b-8892-60a3182cf17f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1  Cost = 163.5827346121474\n",
            "2  Cost = 14.741999214118655\n",
            "3  Cost = 71.95498767699834\n",
            "4  Cost = 67.58006238660589\n",
            "5  Cost = 50.81301651876855\n",
            "6  Cost = 48.159638221243604\n",
            "7  Cost = 68.36681563935919\n",
            "8  Cost = 52.81667824339447\n",
            "9  Cost = 68.75958544494453\n",
            "10  Cost = 53.833464057226806\n",
            "11  Cost = 89.11059535385998\n",
            "12  Cost = 54.07028180651032\n",
            "13  Cost = 17.966686568769383\n",
            "14  Cost = 28.112476423714337\n",
            "15  Cost = 31.034710928341607\n",
            "16  Cost = 42.09277792108207\n",
            "17  Cost = 35.84784833232595\n",
            "18  Cost = 11.775173826555971\n",
            "19  Cost = 20.42286225455132\n",
            "20  Cost = 16.878270840592933\n",
            "21  Cost = 28.87533767364011\n",
            "22  Cost = 24.682084548814696\n",
            "23  Cost = 24.902244165669824\n",
            "24  Cost = 16.449268831321852\n",
            "25  Cost = 20.812936976819376\n",
            "26  Cost = 41.081035733463736\n",
            "27  Cost = 31.995024883478873\n",
            "28  Cost = 28.492870201310154\n",
            "29  Cost = 31.526580588370962\n",
            "30  Cost = 25.168660071951766\n",
            "31  Cost = 16.957140465912524\n",
            "32  Cost = 44.457852801014866\n",
            "33  Cost = 38.2700092904375\n",
            "34  Cost = 19.815690158445324\n",
            "35  Cost = 33.10582975492268\n",
            "36  Cost = 24.803222965092417\n",
            "37  Cost = 40.121783292038785\n",
            "38  Cost = 24.65827618183585\n",
            "39  Cost = 21.41135146380002\n",
            "40  Cost = 24.716211248267275\n",
            "41  Cost = 28.357080156427678\n",
            "42  Cost = 24.145087810551725\n",
            "43  Cost = 28.202879382504452\n",
            "44  Cost = 21.376676291566227\n",
            "45  Cost = 28.199823810252703\n",
            "46  Cost = 39.23076757267365\n",
            "47  Cost = 18.332531125142584\n",
            "48  Cost = 28.114727114474938\n",
            "49  Cost = 17.111385208236555\n",
            "50  Cost = 24.558426302816358\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PythonRDD[95] at RDD at PythonRDD.scala:53"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getWord (inputPosList):\n",
        "  swap_dict = dict((v,k) for k,v in dict_data.items())\n",
        "  for e in inputPosList:\n",
        "    lookup = swap_dict.get(e)\n",
        "    print(\"position: \", e, \"- word: \", lookup, \"- coefficient:\", pv[e])\n",
        "\n",
        "pos_checks = pv.argsort()[-5:][::-1]\n",
        "\n",
        "getWord(pos_checks) #Grab top 5 words with highest coefficient"
      ],
      "metadata": {
        "id": "Y1ccM6MvBc_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cf6254a-5622-4a70-d27b-08599498adb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "position:  12 - word:  that - coefficient: 0.3422171569416813\n",
            "position:  4 - word:  to - coefficient: 0.18433124081245328\n",
            "position:  28 - word:  not - coefficient: 0.1395178633673223\n",
            "position:  22 - word:  be - coefficient: 0.1297499559719862\n",
            "position:  346 - word:  applicant - coefficient: 0.11949478899709662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 3\n",
        "\n",
        "! wget -q https://storage.googleapis.com/met-cs-777-data/SmallTestingData.txt.bz2\n",
        "\n",
        "# Use this code to read the data\n",
        "courtFile2 = 'SmallTestingData.txt.bz2'\n",
        "corpus2 = sc.textFile(courtFile2, 1)"
      ],
      "metadata": {
        "id": "RYABolT2vr-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyAndText2 = corpus2.map(lambda x : (x[x.index('id=\"') + 4 : x.index('\" url=')], x[x.index('\">') + 2:][:-6]))\n",
        "regex = re.compile('[^a-zA-Z]')\n",
        "keyAndListOfWords2 = keyAndText2.map(lambda x : (str(x[0]), regex.sub(' ', str(x[1])).lower().split()))"
      ],
      "metadata": {
        "id": "xm-l2jdHwTIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allDictionaryWords2 = keyAndListOfWords2.flatMap(lambda x: ((j, x[0]) for j in x[1])).map(lambda x: (x[0], (x[1], dict_data.get(x[0]))) if x[0] in dict_data.keys() else None).filter(lambda x: x!=None)\n",
        "\n",
        "allDocsAsNumpyArrays2 = allDictionaryWords2.map(lambda x: (x[1][0], x[1][1])).groupByKey().map(lambda x: (x[0], buildArray(x[1])))"
      ],
      "metadata": {
        "id": "eu1EH4pjwYp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdata = allDocsAsNumpyArrays2.map(lambda x: (x[0], 1 if 'AU' in x[0] else 0, x[1]))\n",
        "\n",
        "print(testdata.take(5))"
      ],
      "metadata": {
        "id": "4zB8dP4qxBOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99b9dfdf-7586-4cea-f3db-ec9d245749f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('AU11', 1, array([0.09323308, 0.04210526, 0.02706767, ..., 0.00075188, 0.        ,\n",
            "       0.        ])), ('AU28', 1, array([0.10257817, 0.05485464, 0.0224904 , ..., 0.        , 0.        ,\n",
            "       0.        ])), ('AU29', 1, array([0.09867374, 0.05145889, 0.01485411, ..., 0.        , 0.        ,\n",
            "       0.        ])), ('AU31', 1, array([0.09686411, 0.03832753, 0.01393728, ..., 0.        , 0.        ,\n",
            "       0.        ])), ('AU38', 1, array([0.09543246, 0.05889213, 0.03401361, ..., 0.00019436, 0.        ,\n",
            "       0.        ]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Bias: \", pv[-1]) #Negative bias, documents which return a 0 theta value are considered '0' rather than '1'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TMz8NDJjYyH",
        "outputId": "45b4873c-1a7a-44c5-b260-bc92259ee1e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bias:  -3.8838974964282182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testresults = testdata.map(lambda x: (x[0], x[1], (np.dot(x[2],pv[:-1])))).map(lambda x: (x[0], x[1], (x[2] > 0).astype(int))) #Use '>' rather than '>=' as bias is negative\n",
        "testresults.cache()\n",
        "\n",
        "print(testresults.take(10))\n",
        "\n",
        "TP = testresults.filter(lambda x: x[1] == 1 and x[2] == 1).count() #TP\n",
        "FP = testresults.filter(lambda x: x[1] == 0 and x[2] == 1).count() #FP\n",
        "FN = testresults.filter(lambda x: x[1] == 1 and x[2] == 0).count() #FN\n",
        "TN = testresults.filter(lambda x: x[1] == 0 and x[2] == 0).count() #TN\n",
        "\n",
        "F1 = TP/(TP + (0.50 * (FP + FN)))\n",
        "\n",
        "print(\"TP: \", TP, \"FP: \", FP, \"FN: \", FN, \"TN: \", TN)\n",
        "print(\"F1 Score: \", F1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdolCWlDxgt0",
        "outputId": "0d51677c-997b-477f-a472-7ff3b0249187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('AU11', 1, 1), ('AU28', 1, 1), ('AU29', 1, 1), ('AU31', 1, 1), ('AU38', 1, 0), ('AU67', 1, 1), ('AU77', 1, 1), ('AU78', 1, 1), ('AU87', 1, 1), ('AU88', 1, 1)]\n",
            "TP:  18 FP:  0 FN:  2 TN:  20\n",
            "F1 Score:  0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "FPs = testresults.filter(lambda x: x[1] == 0 and x[2] == 1).map(lambda x: x[0]) #Look at FPs\n",
        "\n",
        "keyAndText2.cache()\n",
        "\n",
        "def falsePositives (falsePositiveExamples): #Find documents that triggered a FP\n",
        "  example_count = 0\n",
        "  for e in falsePositiveExamples:\n",
        "      print('Document ID:', e, ' -  Document Text: ', keyAndText2.lookup(e))\n",
        "      example_count += 1\n",
        "  if example_count == 0:\n",
        "      print('No False Positives!')\n",
        "\n",
        "falsePositives(FPs.take(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHaTVy6vOR3W",
        "outputId": "fd91d405-c4a7-4d6a-9257-a560512fad14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No False Positives!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc.stop()\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "qfA1htF2H5We"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}